# WandB.
wandb_config:
    WandB: true      # Whether to run this is WandB platform.
    project_name: 'Online IPV Classification'
    entity: 'sagun-shakya'
    run_name: "nepsa_non_concat"
    
# DATA
data_file: ./data/raw
data_path: ./data/kfold
shuffle: true
kfold: 5
verbose: true
data_filename: ipv
cache_dir: ./cache_dir 

# EMBEDDINGS
pretrained: True
emb_dir: ./embeddings
emb_file: model_fasttext_300d__NNC.bin
embedding_dim: 300
embed_finetune: True

# OUTPUT_DIR
output_dir: ./saved_model_dir
results_dir: ./results
log_dir: ./logs

# TRAIN
batch_size: 8
epochs: 80
early_max_patience: 10
log_interval: 100

# OPTIM
learning_rate: 0.05
weight_decay: 0.000001
momentum: 0.0
clip_max_norm_use: False
clip_max_norm: None
use_lr_decay: True
lr_rate_decay: noam_step
learning_rate_warmup_steps: 100
min_lrate: 0.000005
max_patience: 2

# MODELs.
rnn:
    bidirection: true
    num_layers: 1
    hidden_dim: 256
    dropout_embed: 0.0
    dropout: 0.5

cnn:
    num_filters: 100
    filter_sizes: 2,3,4
    dropout_embed: 0.0
    dropout: 0.5

# Vectorizer.
vectorizer:
    mode: count
    max_features: 1000

# SVM.
svm:
    kernel: rbf
    C: 0.1

# Multinomial-NB.
nb:
    alpha: 1.0

# Random Forest.
random_forest:
    n_estimators: 100
    criterion: entropy
    min_samples_split: 3
    min_samples_leaf: 5
    random_state: 1000

# Logistic Regression.
logistic_regression:
    C: 0.01
    max_iter: 100

# AdaBoost Classifier.
adaboost:
    n_estimators: 150
    learning_rate: 0.01
    random_state: 100

# EVALUATION
average: weighted
auc_multiclass: ovr